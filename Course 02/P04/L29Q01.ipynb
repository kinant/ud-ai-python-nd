{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Extract Model Acronyms\n",
    "\n",
    "In this exercise, you'll use a list comprehension to create a new list containing just the acronyms of model names. Each acronym is made by taking the first letter of each word in the model name, converting it to uppercase, and joining the letters together.\n",
    "\n",
    "**Example Input**:\n",
    "```python\n",
    "models = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Support Vector Machine\", \"Naive Bayes\"]\n",
    "```\n",
    "\n",
    "**Example Output**:\n",
    "```python\n",
    "model_acronyms = ['LR', 'DT', 'RF', 'SVM', 'NB']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T19:00:36.075157Z",
     "start_time": "2025-06-03T19:00:36.071552Z"
    }
   },
   "source": [
    "from C02.P04.L16Q01 import initial_lr\n",
    "\n",
    "models = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Support Vector Machine\", \"Naive Bayes\"]\n",
    "model_acronyms = [\"\".join([word[0].upper() for word in model.split()]) for model in models]\n",
    "\n",
    "print(model_acronyms)\n",
    "\n",
    "### Notebook grading\n",
    "correct_answer = ['LR', 'DT', 'RF', 'SVM', 'NB']\n",
    "if model_acronyms == correct_answer:\n",
    "    print(\"Good job!\")\n",
    "else:\n",
    "    print(\"Not quite! Did you create the acronyms correctly?\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LR', 'DT', 'RF', 'SVM', 'NB']\n",
      "Good job!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Learning Rate Decay\n",
    "\n",
    "In this exercise, you'll use a list comprehension to create a list containing the learning rates (LR) a model will see during training, with an initial learning rate of 0.1 and a decay factor of 0.1. The decay is applied multiplicatively for each subsequent step. Generate the learning rates for the first 5 steps.\n",
    "\n",
    "**Example Output**:\n",
    "```python\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T19:05:54.851076Z",
     "start_time": "2025-06-03T19:05:54.847589Z"
    }
   },
   "source": [
    "initial_lr = 0.1\n",
    "decay_factor = 0.1\n",
    "learning_rates = [(initial_lr * (decay_factor ** i)) for i in range(6)]\n",
    "learning_rates = [format(lr, '.6f') for lr in learning_rates]\n",
    "print(learning_rates)\n",
    "\n",
    "### Notebook grading\n",
    "correct_answer = ['0.100000', '0.010000', '0.001000', '0.000100', '0.000010', '0.000001']\n",
    "if learning_rates == correct_answer:\n",
    "    print(\"Good job!\")\n",
    "else:\n",
    "    print(\"Not quite! Are you sure the decay factor is applied correctly for each step?\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.100000', '0.010000', '0.001000', '0.000100', '0.000010', '0.000001']\n",
      "Good job!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Filter Models by Performance\n",
    "\n",
    "In this exercise, you'll use a list comprehension to create a list of model names that achieved at least 85% performance.\n",
    "\n",
    "**Example Input**:\n",
    "```python\n",
    "model_performances = {\n",
    "    \"Logistic Regression\": 90,\n",
    "    \"Decision Tree\": 75,\n",
    "    \"Random Forest\": 92,\n",
    "    \"Support Vector Machine\": 80,\n",
    "    \"Naive Bayes\": 88\n",
    "}\n",
    "```\n",
    "\n",
    "**Example Output**:\n",
    "```python\n",
    "passed_models = ['Logistic Regression', 'Random Forest', 'Naive Bayes']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T19:07:40.384564Z",
     "start_time": "2025-06-03T19:07:40.380514Z"
    }
   },
   "source": [
    "model_performances = {\n",
    "    \"Logistic Regression\": 90,\n",
    "    \"Decision Tree\": 75,\n",
    "    \"Random Forest\": 92,\n",
    "    \"Support Vector Machine\": 80,\n",
    "    \"Naive Bayes\": 88\n",
    "}\n",
    "\n",
    "passed_models = [perf for perf, acc in model_performances.items() if acc >= 85]\n",
    "\n",
    "### Notebook grading\n",
    "correct_answer = ['Logistic Regression', 'Random Forest', 'Naive Bayes']\n",
    "if passed_models == correct_answer:\n",
    "    print(\"Good job!\")\n",
    "else:\n",
    "    print(\"Not quite! Did you use the corresponding performance to filter each model?\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good job!\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
