{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Execution Time of `map`, `filter`, and Conventional For-Loops\n",
    "\n",
    "In AI and data processing, efficiency is crucial. Let's compare the execution times of `map`, `filter`, and conventional for-loops to understand the performance benefits of using higher-order functions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:32:38.268846Z",
     "start_time": "2025-06-04T20:32:37.922414Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "# Sample data\n",
    "numbers = list(range(1, 1000000))\n",
    "threshold = 500000\n",
    "\n",
    "# Conventional for-loop for map equivalent (square of each number)\n",
    "start_time = time.time()\n",
    "squares_conventional = []\n",
    "for num in numbers:\n",
    "    squares_conventional.append(num ** 2)\n",
    "end_time = time.time()\n",
    "conventional_map_time = end_time - start_time\n",
    "\n",
    "# Using map\n",
    "start_time = time.time()\n",
    "squares_map = map(lambda x: x ** 2, numbers)\n",
    "end_time = time.time()\n",
    "map_time = end_time - start_time\n",
    "\n",
    "# Conventional for-loop for filter equivalent (numbers greater than threshold)\n",
    "start_time = time.time()\n",
    "filtered_conventional = []\n",
    "for num in numbers:\n",
    "    if num > threshold:\n",
    "        filtered_conventional.append(num)\n",
    "end_time = time.time()\n",
    "conventional_filter_time = end_time - start_time\n",
    "\n",
    "# Using filter\n",
    "start_time = time.time()\n",
    "filtered_filter = filter(lambda x: x > threshold, numbers)\n",
    "end_time = time.time()\n",
    "filter_time = end_time - start_time\n",
    "\n",
    "# Printing the results\n",
    "print(f\"Conventional for-loop (map equivalent) took: {conventional_map_time:.6f} seconds\")\n",
    "print(f\"Map function took: {map_time:.6f} seconds\")\n",
    "print(f\"Conventional for-loop (filter equivalent) took: {conventional_filter_time:.6f} seconds\")\n",
    "print(f\"Filter function took: {filter_time:.6f} seconds\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conventional for-loop (map equivalent) took: 0.166036 seconds\n",
      "Map function took: 0.018001 seconds\n",
      "Conventional for-loop (filter equivalent) took: 0.122518 seconds\n",
      "Filter function took: 0.001003 seconds\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Lambda Functions, Map, and Filter\n",
    "\n",
    "**Lambda Functions**: Lambda functions are small, anonymous functions defined using the `lambda` keyword. They are often used for short, simple operations that are not reused elsewhere. A lambda function can take any number of arguments but only has one expression.\n",
    "\n",
    "**Map Function**: The `map()` function applies a given function to all items in an input list (or any other iterable) and returns an iterator with the results. This is particularly useful for transforming data in a concise and readable manner.\n",
    "\n",
    "**Filter Function**: The `filter()` function constructs an iterator from elements of an iterable for which a function returns true. It is commonly used to extract items that meet certain criteria from a dataset.\n",
    "\n",
    "Let's explore these concepts through practical exercises related to managing large datasets in AI projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Normalizing Dataset Sizes with Lambda and Map\n",
    "\n",
    "#### Scenario:\n",
    "\n",
    "You are analyzing datasets of various sizes for an AI project and need to normalize the values in each dataset. **Normalization** ensures that all values are scaled to a similar range, preventing features with larger values from dominating the model. This is a crucial preprocessing step in many AI applications.\n",
    "\n",
    "#### Task:\n",
    "\n",
    "Normalize the values in each dataset using a **min-max normalization** formula within the `map()` function.\n",
    "\n",
    "Normalization Explanation:\n",
    "\n",
    "We will apply **min-max normalization**, which scales the values to a range of **0** to **1** using the following formula:\n",
    "\n",
    "\n",
    "$$X{\\prime} = \\frac{X - X_\\text{min}}{X_\\text{max} - X_\\text{min}}$$\n",
    "\n",
    "\n",
    "where:\n",
    "* $X{\\prime}$ is the normalized value,\n",
    "* $X$ is the original value,\n",
    "* $X_\\text{min}$ and $X_\\text{max}$\tare the minimum and maximum values in the dataset.\n",
    "\n",
    "**Example Input:**\n",
    "```python\n",
    "numbers = [\n",
    "    [34, 63, 88, 71, 29],\n",
    "    [90, 78, 51, 27, 45],\n",
    "    [63, 37, 85, 46, 22],\n",
    "    [51, 22, 34, 11, 18]\n",
    "]\n",
    "```\n",
    "**Example Output (After Min-Max Normalization):**\n",
    "```python\n",
    "[\n",
    "    [0.08, 0.58, 1.00, 0.71, 0.00],\n",
    "    [1.00, 0.81, 0.38, 0.00, 0.29],\n",
    "    [0.65, 0.24, 1.00, 0.38, 0.00],\n",
    "    [1.00, 0.28, 0.57, 0.00, 0.18]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:52:30.606406Z",
     "start_time": "2025-06-04T20:52:30.598406Z"
    }
   },
   "source": [
    "numbers = [\n",
    "    [34, 63, 88, 71, 29],\n",
    "    [90, 78, 51, 27, 45],\n",
    "    [63, 37, 85, 46, 22],\n",
    "    [51, 22, 34, 11, 18]\n",
    "]\n",
    "\n",
    "# Use a lambda function within map to normalize the datasets\n",
    "norm_func = lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "normalized_data = list(map(lambda x: [num / (sum(x) / len(x)) for num in x], numbers))\n",
    "\n",
    "normalized_data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5964912280701754,\n",
       "  1.105263157894737,\n",
       "  1.543859649122807,\n",
       "  1.2456140350877194,\n",
       "  0.5087719298245614],\n",
       " [1.5463917525773194,\n",
       "  1.3402061855670102,\n",
       "  0.8762886597938144,\n",
       "  0.46391752577319584,\n",
       "  0.7731958762886597],\n",
       " [1.2450592885375493,\n",
       "  0.7312252964426877,\n",
       "  1.6798418972332014,\n",
       "  0.9090909090909091,\n",
       "  0.43478260869565216],\n",
       " [1.875, 0.8088235294117647, 1.25, 0.40441176470588236, 0.6617647058823529]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed Exercise 2: Filtering Datasets by Variance with Lambda and Filter\n",
    "#### Scenario:\n",
    "You need to filter datasets that have a variance above a specified threshold. Variance is a measure of the dispersion of data points and helps in identifying datasets with significant variability, which can be crucial for certain AI applications.\n",
    "\n",
    "#### Task:\n",
    "Filter datasets that have a variance above a specified threshold using a lambda function within the `filter()` function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:52:41.361431Z",
     "start_time": "2025-06-04T20:52:41.353373Z"
    }
   },
   "source": [
    "datasets = [\n",
    "    [34, 63, 88, 71, 29],\n",
    "    [90, 78, 51, 27, 45],\n",
    "    [63, 37, 85, 46, 22],\n",
    "    [51, 22, 34, 11, 18]\n",
    "]\n",
    "\n",
    "# Calculate variance for each dataset\n",
    "def variance(num_list):\n",
    "    mean_val = sum(num_list) / len(num_list)\n",
    "    return sum((x - mean_val) ** 2 for x in num_list) / len(num_list)\n",
    "\n",
    "# Filter datasets with variance above a threshold using a lambda function\n",
    "threshold = 400\n",
    "filtered_datasets = list(filter(lambda x: variance(x) > threshold, datasets))\n",
    "\n",
    "filtered_datasets"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[34, 63, 88, 71, 29], [90, 78, 51, 27, 45], [63, 37, 85, 46, 22]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
